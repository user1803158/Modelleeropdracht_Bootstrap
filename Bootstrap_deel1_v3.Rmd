---
title: "Modelleren: statistiekproject"
date: '2023-02-23'
output: pdf_document
---

```{r}
rm(list = ls())
```

# Page 1: getting acquinted with the topic

## Generate data
```{r}
# make outcomes reproducible
set.seed(123)

# create data
data <- rnorm(25, mean = 0, sd = 2)
MLE.data <- sum(data^2)/length(data)
```

## Variance is known
```{r}
# set parameters
N <- 10000
n <- 25
mu <- 0
sd <- 2 

# create samples 
samples <- replicate(N, rnorm(n, mu, sd))

# calculate MLE for each sample 
MLE.samples <- apply(samples, 2, function(x) sum(x^2)/n)

# estimate variance of calculated MLE's
sum((MLE.samples - sum(MLE.samples)/N)^2)/N
```

## Variance is unknown - parametric bootstrap
```{r}
# set new parameter
sd.boot <- sqrt(MLE.data)

# create samples 
samples.boot <- replicate(N, rnorm(n, mu, sd.boot))
```

# Page 2: the assignment
```{r}
rm(list = ls())
```

## Part 1: simulation

### Parametric bootstrap 
```{r}
set.seed(123)

# sets of parameters
N <- c(1, 10, 20, 100, 1000, 10000)
n <- c(1, 10, 20, 100, 1000, 10000)
mu <- 0
sd <- 2 

# create objects to save outcomes
samples.parboot <- replicate(length(N), vector("list", length(n)), 
                             simplify = FALSE)
MLE.parboot <- replicate(length(N), vector("list", length(n)), 
                             simplify = FALSE)
var.parboot <- matrix(nrow = length(N), ncol = length(n))

# create samples for each different parameter + calculate MLE
for(i in 1:length(N)){
  for(j in 1:length(n)){
    # create samples
    samples.parboot[[i]][[j]] = replicate(N[i], rnorm(n[j], mu, sd))
    
    # calculate MLE for each sample
    if(!is.null(dim(samples.parboot[[i]][[j]]))){
      MLE.parboot[[i]][[j]] = apply(samples.parboot[[i]][[j]], 2, function(x) sum(x^2)/n[j])
    }
    else{
      if(N[i] == 1) MLE.parboot[[i]][[j]] = sum(samples.parboot[[i]][[j]]^2)/n[j]
      else MLE.parboot[[i]][[j]] = samples.parboot[[i]][[j]]^2
    }
    
    # calculate variance of MLE's for each sample
    var.parboot[i,j] <- sum((MLE.parboot[[i]][[j]] - sum(MLE.parboot[[i]][[j]])/N[i])^2)/N[i]
  }
}
```

### Non-parametric bootstrap 
```{r}
set.seed(456)

# sets of parameters
N <- c(1, 10, 20, 100, 1000, 10000)
n <- c(1, 10, 20, 100, 1000, 10000)
mu <- 0
sd <- 2 

# create objects to save outcomes
samples.npboot <- replicate(length(N), vector("list", length(n)), 
                             simplify = FALSE)
MLE.npboot <- replicate(length(N), vector("list", length(n)), 
                             simplify = FALSE)
var.npboot <- matrix(nrow = length(N), ncol = length(n))

# create samples for each different parameter + calculate MLE
for(i in 1:length(N)){
  for(j in 1:length(n)){
    # create data
    data.npboot <- rnorm(n[j], mu, sd)
    MLE.data <- sum(data.npboot^2)/n[[j]]
      
    # create non-parametric samples
    samples.npboot[[i]][[j]] = replicate(N[i], rnorm(n[j], mu, sqrt(MLE.data)))
    
    # calculate MLE for each sample
    if(!is.null(dim(samples.npboot[[i]][[j]]))){
      MLE.npboot[[i]][[j]] = apply(samples.npboot[[i]][[j]], 2, function(x) sum(x^2)/n[j])
    }
    else{
      if(N[i] == 1) MLE.npboot[[i]][[j]] = sum(samples.npboot[[i]][[j]]^2)/n[j]
      else MLE.npboot[[i]][[j]] = samples.npboot[[i]][[j]]^2
    }
    
    # calculate variance of MLE's for each sample
    var.npboot[i,j] <- sum((MLE.npboot[[i]][[j]] - sum(MLE.npboot[[i]][[j]])/N[i])^2)/N[i]
  }
}
```

Ideeen voor monsterfunctie: 
- Input
  - Verdelingen: werkelijke verdeling, geschatte verdeling, 
  - Bootstrap: parametric, non-parametric
  - Estimators: MLE, (andere estimator?)
  - Sample sizes:N, n
  - Parameters: theta
- Output:
  - Werkelijke variantie vd schatter
  - Geschatte variantie vd schatter: parametric 
  - Geschatte variantie vd schatter: non-parametric
  - Data 
  - Bootstrap samples
  - Bootstrap estimators 
